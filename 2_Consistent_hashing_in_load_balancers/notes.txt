Load balancer 

Image-1 
    1. Let's say when we are getting request, we are giving it a unique request ID. 
    2. Now let us hash that request ID and the answer will be mod by N where n is the number of the servers. 
        We had the request ID because it could be a large alpha numeric value.
        hash(request_id)%n=server_alloted 
    3. This can be a good approach but it was used in very ancient times. 
    4. So when a particular use of with its unique request ID goes to the load balancer the hash is always 
        same so it will go to a particular server every time. This means that the particular server can store 
        some of that users information in cache because the server even knows that if that particular user 
        request again to the load balance sir then the load balancer will assign that request to the to the same 
        server. 
    5. But what will happen if we try to increase the number of servers. Let save it try to include one more 
        server. Initially in the image one we were distributing the load among four server, but now we are 
        distributing it among five servers. Now each server will need to give some of its request ID share to 
        the new server. Before server 5 every server was getting about 25% of the request but now after server 
        5 every server will get 20% of the request that means 5% of the request of every server it shared with 
        the new server. 
    6. Now the information is totally disturbed I mean of cache. Now all the servers will need to 
        reconfigure it again about the cache. So consistent hashing is a technique used to distribute the 
        request ID within the servers when a new server comes.

Consistent hashing 

    The earlier technique we saw to solve the problem of the load balance sir was good but was not perfect. It 
    was solving very much the problem of distributing the load among multiple servers but when a new server gets 
    added to the system then it was affecting more number of the servers. This problem is solved by consistent 
    hashing. 

Image-2 
    1. In this as we can see there are four servers and their are m requests. 
    2. We are going to Hash the request ID and store in the manner of a ring in such a way that (M-1)th request 
        and 0th request are next to each other. We even hash the server ID's and map that server on the ring. 
    3. In a final structure we have all the request ID map in the ring and even we can see the red servers in 
        between the request id. Now if we have a consistent hashing function of server then all the service will be 
        separated by a uniform distance. 
    4. So when we receive a request we travel in clockwise direction and get the server. And that server will be 
        responsible to respond to that request. 
    5. Even here the request are uniformly distributed among the servers because if the hatching function is 
        uniform then every server is separated by the uniform distance that is every server is responsible for the 
        equal number of requests. 
        image-3
    6. So now let's try to add a new server to it. What will happen, a new server ID will be created and we will 
        hash that. And that has the value we will get a position on that ring and place that server on to it. We can 
        see that the new server s4 is placed between s2 and s3. 
    7. Now we can see the distribution is not uniform so what we do is increase the number of hashing of the 
        servers. We introduce K hash functions. We have each server K Times which means we have key instances of 
        single server and be place each one of the instance on the ring. So by doing it if we add a new server 
        anywhere there will be a uniform distribution of the request as well. 

Image-4
    8 . Problem :- now there is one problem . As we can see in the image for what will happen if one server is 
            removed here we remove server 1(s1). Now all the request which was behind the server 1 will be fetched by 
            the server 2 and all request are not uniformly distributed but they are only gone to the server 2. This is 
            a problem. 
        Solution :- this solution is same, we used k hash funtions to hash the server id's. And place that servers 
            on the ring. Now there exist multiple instances of a single server so now from where we have removed the S1 
            there exist more number of the servers so here the change of adding a new server or removing the existing 
            server does not affects the entire system with the request IDs. If you take the average stil the request 
            id's are uniformly distributed.